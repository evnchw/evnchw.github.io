---
title: "[in progress] Notes on the master equation in mean field games (Delarue 2021)"
collection: quant
type: "Post"
permalink: /quant/20240818_mfg_master_equation
date: 2024-08-18
---

These are my informal notes on the master equation in mean field game theory, closely following the sketch in [Delarue (2021)](https://www.ams.org/meetings/shortcourse/Delarue_AMS.pdf) and supplemented when necessary.

See the reference for full details. All errors are mine.

## What is a master equation?

From physics: the idea is to have a unified equation to model the evolution of a system over time and (probabilistic) states. [(Wiki)](https://en.wikipedia.org/wiki/Master_equation)

> When the probabilities of the elementary processes are known, one can write down a continuity equation for W, from which all other equations can be derived and which we will call therefore the "master‚Äù equation.

## Basic setup

Let players be $i \in \{1 \dots N\}$ and times $t \in \mathcal{T} = \{1 \dots T\}$. Each player $i$ has a dynamic $d$-dimensional state $X^i_t \in \mathbb{R}^d$, which follows the dynamics:

$$
\begin{align}
    dX_t^i &= \alpha_t^i dt + dW_t^i & t \in [0, T]
\end{align}
$$

with an idiosyncratic Brownian motion $W_t^i$ and progressively-measurable process $\{a_t^i\}_{t \in \mathcal{T}}$, where all the $(W_t^j, a_t^j)$ are independent across all players $j$. Initial conditions IID.

$i$ faces the cost functional:

$$
\begin{align}
    J^i (\bold{\alpha}^1, \dots, \bold{\alpha}^N) &= \mathbb{E}\left[
        g(X_T^i, \bar{\mu}_T^N) +
        \int_0^T \left(f(X_t^i, \bar{\mu}_t^N) + \frac{1}{2} |\alpha_t^i|^2\right) dt
    \right] &\text{cost functional} \\
    \bar{\mu}_t^N &= \frac{1}{N} \sum_{i=1}^N \delta_{X_t^i} &\text{empirical measure}
\end{align}
$$

noting $\alpha^i$ is a stochastic process $\{\alpha^i_t\}$. Intuitively, player $i$ controls its strategy $\alpha^i$ to optimize $J^i$, against the strategies of other players $\alpha^j$ for $j \neq i$.

## The mean field game (MFG) problem

Generalizing this (and removing subscripts $i$), let us formulate the mean field game problem.

First, the state dynamics for any identical agent still follow the above dynamics.

$$
\begin{align}
    d X_t &= \alpha_t dt + d W_t
\end{align}
$$

Second, the distribution of these agent states evolves as a flow of probability measures $\{\mu_t\}_{t \in \mathcal{T}}$, where $\mu_t \in \mathcal{P}_2(\mathbb{R}^d)$, that is, the space of probability measures of $\mathbb{R}^d$ with finite second moments.

Third, any identical agent solves the cost function according to an identical strategy $\alpha = \{a_t\}_{t \in \mathcal{T}}$:

$$
\begin{align}
    J(\alpha) &= \mathbb{E} \left[
        g(X_T, \mu_T) + \int_0^T \left( f(X_t, \mu_t) +\frac{1}{2} |a_t|^2 \right) dt
    \right]
\end{align}
$$

noting that this requires the mean field flow $\{\mu_t\}_t$.

Lastly, the initial condition is that $X_0 \in \mathbb{R}^d$ is defined on a probability space $(\Omega, \mathcal{F}, \mathbb{P})$.

The goal of the mean field game problem is to find $\mu_t$ such that we have a fixed point with the states (that themselves in return are determined by $\mu_t$). Assuming there is a unique optimizer $\{X_t^{*, \mu}\}_{t \in \mathcal{T}}$, the fixed point problem is:

$$
\begin{align}
    \mu_t &= \mathcal{L}(X_t^{*, \mu}) & \forall t \in \mathcal{T}
\end{align}
$$

This specifies a mean field in the (distribution of) states. The scheme is to find $\forall t: \mu_t \mapsto X_t^{*} \mapsto \mu_t$, such that each agent optimizes their state ($X_t^*$) against the mean field ($\mu_t$), and in return the mean field is generated by the states. Presumably there is an associated optimal control $a_t^{*}$ that generates the $X_t^{*}$ and therefore the mean field.

## The MFG problem, reformulated as a PDE

